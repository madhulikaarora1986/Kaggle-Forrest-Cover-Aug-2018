{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/dmlc/xgboost/blob/master/python-package/xgboost/sklearn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tqchen/xgboost/blob/master/demo/guide-python/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.XGBClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb.XGBClassifier(self, max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['Id','Cover_Type'],1)\n",
    "Y_train = train['Cover_Type']\n",
    "X_test = test.drop(['Id'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_tf = pd.DataFrame(scaler.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
    "X_test_tf = pd.DataFrame(scaler.transform(X_test),index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, eval_metric='mlogloss', gamma=0.5,\n",
       "       learning_rate=1.2, max_delta_step=0, max_depth=12,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=4,\n",
       "       nthread=None, num_class=7, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0.01, reg_lambda=10, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Led to overfitting\n",
    "#xgbc=xgb.XGBClassifier(objective='multi:softprob',n_jobs=4,learning_rate=1.2,num_class=7,eval_metric=\"mlogloss\")\n",
    "#0.97169312169312172\n",
    "#[ 0.74603175  0.71990741  0.73941799  0.75198413  0.82010582]\n",
    "\n",
    "#xgbc=xgb.XGBClassifier(objective='multi:softprob',n_jobs=4,learning_rate=1.2,num_class=7,eval_metric=\"mlogloss\",reg_lambda=5)\n",
    "#0.95932539682539686\n",
    "#[ 0.74272487  0.72354497  0.73842593  0.7582672   0.81316138]\n",
    "\n",
    "#xgbc=xgb.XGBClassifier(objective='multi:softmax',n_jobs=4,learning_rate=1.2,num_class=7,eval_metric=\"mlogloss\",reg_lambda=5)\n",
    "#0.95932539682539686\n",
    "#[ 0.74272487  0.72354497  0.73842593  0.7582672   0.81316138]\n",
    "\n",
    "#xgbc=xgb.XGBClassifier(objective='multi:softprob',n_jobs=4,learning_rate=1.2,num_class=7,eval_metric=\"mlogloss\",reg_lambda=10, reg_alpha=0.01)\n",
    "\n",
    "xgbc=xgb.XGBClassifier(objective='multi:softprob'\n",
    "                       ,n_jobs=4\n",
    "                       ,learning_rate=1.2\n",
    "                       ,num_class=7\n",
    "                       ,eval_metric=\"mlogloss\"\n",
    "                       ,reg_lambda=10\n",
    "                       ,reg_alpha=0.01\n",
    "                       ,colsample_bytree=0.5\n",
    "                       ,subsample=0.5\n",
    "                       ,gamma=0.5\n",
    "                       ,max_depth=12)\n",
    "\n",
    "xgbc.fit(X_train_tf,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 2, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred = xgbc.predict(X_train_tf)\n",
    "Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99484126984126986"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.accuracy_score(Y_train,Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7364418   0.72850529  0.76289683  0.77083333  0.83465608]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76666666666666672"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgbc=xgb.XGBClassifier(objective='multi:softprob'\n",
    "#                        ,n_jobs=4\n",
    "#                        ,eta=0.2\n",
    "#                        ,num_class=7\n",
    "#                        ,eval_metric=\"mlogloss\"\n",
    "#                        ,reg_lambda=10\n",
    "#                        ,reg_alpha=0.01\n",
    "#                        ,colsample_bytree=0.5\n",
    "#                        ,subsample=0.5\n",
    "#                        ,gamma=1.5\n",
    "#                        ,max_depth=12)\n",
    "\n",
    "xgbc=xgb.XGBClassifier(objective = \"multi:softmax\",\n",
    "                       eval_metric = \"merror\",\n",
    "                       max_depth = 12,\n",
    "                       eta = 0.0399,\n",
    "                       gamma = 1.2393,\n",
    "                       subsample = 0.7052,\n",
    "                       colsample_bytree = 0.6296,\n",
    "                       min_child_weight = 7,\n",
    "                       colsample_bylevel = 1,\n",
    "                       reg_lambda = 1, \n",
    "                       reg_alpha = 0, \n",
    "                       num_class = 7,\n",
    "                       booster = \"gbtree\",\n",
    "                       silent = 0)\n",
    "results=cross_val_score(xgbc,X_train,Y_train,cv=5,n_jobs=8)\n",
    "print(results)\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_estimators = [20,40,60,80]\n",
    "Criterion = ['gini','entropy']\n",
    "Max_depth = [20,30,40,50,60,70]\n",
    "i=0\n",
    "for n_estimator in N_estimators:\n",
    "    for criterion in Criterion:\n",
    "        for max_depth in Max_depth:\n",
    "            results_rf.loc[i,'n_estimator'] = n_estimator\n",
    "            results_rf.loc[i,'criterion'] = criterion\n",
    "            results_rf.loc[i,'max_depth'] = max_depth\n",
    "            r = cross_val_score(RandomForestClassifier(n_estimators=n_estimator,\n",
    "                                                       criterion=criterion,\n",
    "                                                      max_depth=max_depth,\n",
    "                                                      random_state=100),\n",
    "                               X=X_train_tf,y=Y_train,scoring='accuracy',cv=5,n_jobs=4)\n",
    "            results_rf.loc[i,'accuracy_min'] = r.min()\n",
    "            results_rf.loc[i,'accuracy_max'] = r.max()\n",
    "            results_rf.loc[i,'accuracy_mean'] = r.mean()\n",
    "            i = i+1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
